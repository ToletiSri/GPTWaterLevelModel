{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5c83a14d",
   "metadata": {},
   "source": [
    "# Carnival Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "630acc2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import serial\n",
    "from LatLongMap import latitude_values, longitude_values\n",
    "from gpt import GPTWaterLevelModel\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a1d93ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cpu'\n",
    "start_row = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "706b8908",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getIndexForXposition(x, start_value = 45.00, end_value = 3.00, step = 0.01, num_indices = 275):\n",
    "    normalised_position = (start_value - x)/(start_value - end_value)\n",
    "    index = normalised_position * (num_indices - 1)\n",
    "    index = abs(int(index))\n",
    "    #print(index)\n",
    "    return index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9326ee8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def createDataForModel(tensor, stack_vector):\n",
    "    tensor = tensor.unsqueeze(0).unsqueeze(0)\n",
    "    # If stack_vector is initially of size [1, 0, 0], initialize it with the new tensors\n",
    "    if stack_vector.size() == torch.Size([1, 0, 0]):\n",
    "        stack_vector = tensor\n",
    "    else:\n",
    "        # Otherwise, concatenate the new tensors along the second dimension\n",
    "        #new_tensor = torch.stack(tensor).unsqueeze(0).unsqueeze(0)\n",
    "        stack_vector = torch.cat((stack_vector, tensor), dim=1)    \n",
    "    return stack_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8329f5d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getNextCoordinates(stack_vector, count=4):\n",
    "    nextLatLong = torch.empty((1,0, 0))\n",
    "    #Get the lat and long from the last element of the vector\n",
    "    last_entry_lat_long = stack_vector[0, -1, 0:2]\n",
    "    #print(last_entry_lat_long)\n",
    "    #Find the index of current latitude\n",
    "    lat = last_entry_lat_long[0]   \n",
    "    ##print(lat)\n",
    "    index = latitude_values.index(lat)\n",
    "    #print(index)\n",
    "    for i in range(count):\n",
    "        index = index+1\n",
    "        tensor = torch.tensor([latitude_values[index], longitude_values[index]], dtype=torch.float32, device=device)\n",
    "        tensor = tensor.unsqueeze(0).unsqueeze(0)\n",
    "        if nextLatLong.size() == torch.Size([1, 0, 0]):\n",
    "            nextLatLong = tensor\n",
    "        else:\n",
    "            nextLatLong = torch.cat((nextLatLong, tensor),dim = 1)\n",
    "    return nextLatLong   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daea7d3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sendInfoToHMI(CurrentWaterLevels, predicted_water_levels):\n",
    "    global start_row\n",
    "    CurrentWaterLevels = CurrentWaterLevels[:, -1: , :].squeeze()\n",
    "    array1 = CurrentWaterLevels.numpy().flatten()\n",
    "    #print(array1.size)\n",
    "    predicted_water_levels = predicted_water_levels.squeeze()\n",
    "    array2 = predicted_water_levels.numpy().flatten()\n",
    "    #print(array2.size)    \n",
    "    combined_array = np.hstack((array1, array2))\n",
    "    #print(combined_array.size)\n",
    "    # df_combined = pd.DataFrame([combined_array], columns = [f'Column{i+1}' for i in range(combined_array.size)])\n",
    "    # df_combined.to_excel('ToHMI.xlsx', sheet_name='tohmi',index=False, startrow=start_row)\n",
    "    # start_row = start_row + 1\n",
    "    values_list = combined_array.flatten().astype(str).tolist()\n",
    "    with open('ToHMI.txt','a') as file:\n",
    "        line = '\\t'.join(values_list)\n",
    "        file.write(line + '\\n')\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1203107",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getWaterLevelPredictions(CurrentWaterLevels, model):\n",
    "    next_coordinates = getNextCoordinates(CurrentWaterLevels)\n",
    "    #print(next_coordinates)\n",
    "    #print(CurrentWaterLevels)\n",
    "    CurrentWaterLevels = CurrentWaterLevels[:, -8: , :]\n",
    "    predicted_water_levels = model.generate(CurrentWaterLevels, 4, next_coordinates) \n",
    "    print(f'Current 8(upto) water levels = {[round(value, 4) for value in CurrentWaterLevels[:,:,-1].tolist()[0]]}' )\n",
    "    print(f'Predicted next 4 water levels = {[round(value,4) for value in predicted_water_levels[:,8:,-1].tolist()[0]]}' )\n",
    "    sendInfoToHMI(CurrentWaterLevels, predicted_water_levels[:,8:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b19e1563",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(ser):    \n",
    "    global prev_depth\n",
    "    global prev_loc\n",
    "    \n",
    "    if ser.in_waiting > 0:\n",
    "        raw_data = ser.readline().strip()\n",
    "        raw_data.decode('latin1')\n",
    "        #buf = ser.readline().decode('utf-8').rstrip()\n",
    "        buf = str(raw_data).rstrip(\"\\n\")\n",
    "        #print(buf)\n",
    "        start = buf.find('[')\n",
    "        #print(start)\n",
    "        buf = buf[start+1:]\n",
    "        end = buf.find(']')\n",
    "        #print(end)\n",
    "        msg_parts = buf[:end].split(\";\") # buf now has depth, x-axis\n",
    "        #print(msg_parts)\n",
    "        curWaterDepth = float(msg_parts[0])\n",
    "        x_position = float(msg_parts[1])\n",
    "        if (x_position >= 8.0) and (x_position <= 44.25) and (x_position < prev_loc) and (curWaterDepth < prev_depth):\n",
    "            prev_loc = x_position\n",
    "            prev_depth = curWaterDepth\n",
    "            index = getIndexForXposition(float(msg_parts[1]))\n",
    "            #print(index)\n",
    "            lat = latitude_values[index]\n",
    "            long = longitude_values[index]\n",
    "            tensor = torch.tensor([lat, long, curWaterDepth], dtype=torch.float32, device=device)      \n",
    "            return tensor\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44fa72b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "running = True\n",
    "ser = serial.Serial(\"COM9\", 9600)\n",
    "saved_model = GPTWaterLevelModel(800)\n",
    "saved_model.load_state_dict(torch.load('saved_model_new.pth', map_location=torch.device('cpu')))\n",
    "LatLongDepthTensor = torch.empty((1, 0, 0))\n",
    "while running:\n",
    "    tensor = read_data(ser)    \n",
    "    if tensor is not None:\n",
    "        #print(tensor)\n",
    "        LatLongDepthTensor = createDataForModel(tensor, LatLongDepthTensor)\n",
    "        getWaterLevelPredictions(LatLongDepthTensor, saved_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f40b6a50",
   "metadata": {},
   "outputs": [],
   "source": [
    "ser.close() \n",
    "prev_depth = 100\n",
    "prev_loc = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3297c953",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_excel('dataset5.xlsx')\n",
    "# water_depth = df.iloc[:, 0]\n",
    "# x_pos = df.iloc[:, 1]\n",
    "# start_value = 45.00\n",
    "# end_value = 3.00\n",
    "# step = 0.01\n",
    "# num_indices = 275\n",
    "# normalised_position = (start_value - x_pos.values)/(start_value - end_value)\n",
    "# index = normalised_position * (num_indices - 1)\n",
    "# indices = [abs(int(x)) for x in index]\n",
    "# lat = [latitude_values[x] for x in indices]\n",
    "# long = [longitude_values[x] for x in indices]\n",
    "# df2 = pd.DataFrame({'lat':lat, 'long':long, 'depth':water_depth})\n",
    "# df2.to_excel('ActLatLongDepth1.xlsx', index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "742c38be",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\srtoleti\\AppData\\Local\\Temp\\ipykernel_33388\\3341988633.py:4: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  saved_model.load_state_dict(torch.load('saved_model_new.pth', map_location=torch.device('cpu')))\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[58], line 9\u001b[0m\n\u001b[0;32m      7\u001b[0m prev_loc \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1000\u001b[39m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m running:\n\u001b[1;32m----> 9\u001b[0m     tensor \u001b[38;5;241m=\u001b[39m \u001b[43mread_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mser\u001b[49m\u001b[43m)\u001b[49m    \n\u001b[0;32m     10\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m tensor \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     11\u001b[0m         \u001b[38;5;66;03m#print(tensor)\u001b[39;00m\n\u001b[0;32m     12\u001b[0m         LatLongDepthTensor \u001b[38;5;241m=\u001b[39m createDataForModel(tensor, LatLongDepthTensor)\n",
      "Cell \u001b[1;32mIn[53], line 6\u001b[0m, in \u001b[0;36mread_data\u001b[1;34m(ser)\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mglobal\u001b[39;00m prev_loc\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ser\u001b[38;5;241m.\u001b[39min_waiting \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m----> 6\u001b[0m     raw_data \u001b[38;5;241m=\u001b[39m \u001b[43mser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreadline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mstrip()\n\u001b[0;32m      7\u001b[0m     raw_data\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlatin1\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;66;03m#buf = ser.readline().decode('utf-8').rstrip()\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\srtoleti\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\serial\\serialwin32.py:288\u001b[0m, in \u001b[0;36mSerial.read\u001b[1;34m(self, size)\u001b[0m\n\u001b[0;32m    286\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m read_ok \u001b[38;5;129;01mand\u001b[39;00m win32\u001b[38;5;241m.\u001b[39mGetLastError() \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m (win32\u001b[38;5;241m.\u001b[39mERROR_SUCCESS, win32\u001b[38;5;241m.\u001b[39mERROR_IO_PENDING):\n\u001b[0;32m    287\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m SerialException(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReadFile failed (\u001b[39m\u001b[38;5;132;01m{!r}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(ctypes\u001b[38;5;241m.\u001b[39mWinError()))\n\u001b[1;32m--> 288\u001b[0m result_ok \u001b[38;5;241m=\u001b[39m \u001b[43mwin32\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mGetOverlappedResult\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    289\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_port_handle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    290\u001b[0m \u001b[43m    \u001b[49m\u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbyref\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_overlapped_read\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    291\u001b[0m \u001b[43m    \u001b[49m\u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbyref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrc\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    292\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    293\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m result_ok:\n\u001b[0;32m    294\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m win32\u001b[38;5;241m.\u001b[39mGetLastError() \u001b[38;5;241m!=\u001b[39m win32\u001b[38;5;241m.\u001b[39mERROR_OPERATION_ABORTED:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# running = True\n",
    "# ser = serial.Serial(\"COM9\", 9600)\n",
    "# saved_model = GPTWaterLevelModel(800)\n",
    "# saved_model.load_state_dict(torch.load('saved_model_new.pth', map_location=torch.device('cpu')))\n",
    "# LatLongDepthTensor = torch.empty((1, 0, 0))\n",
    "# prev_depth = 100\n",
    "# prev_loc = 1000\n",
    "# while running:\n",
    "#     tensor = read_data(ser)    \n",
    "#     if tensor is not None:\n",
    "#         #print(tensor)\n",
    "#         LatLongDepthTensor = createDataForModel(tensor, LatLongDepthTensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "185b173a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 3])\n"
     ]
    }
   ],
   "source": [
    "# ser.close() \n",
    "# prev_depth = 100\n",
    "# prev_loc = 1000\n",
    "# LatLongDepthTensor = LatLongDepthTensor.squeeze(0)\n",
    "# print(LatLongDepthTensor.size())\n",
    "# lat = LatLongDepthTensor[:,0].tolist()\n",
    "# long = LatLongDepthTensor[:,1].tolist()\n",
    "# water_depth = LatLongDepthTensor[:,2].tolist()\n",
    "# df2 = pd.DataFrame({'lat':lat, 'long':long, 'depth':water_depth})\n",
    "# df2.to_excel('TrainLatLongDepth16.xlsx', index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b423b9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "LatLongDepthTensor"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
